# CNN 

```{r}
library (caret)
library(nnet)
```


```{r}
data <- read.csv("train.csv")
test_df <- read.csv("test.csv")

data$label <- as.factor(data$label)
summary(data$label) #Cantidad de imagenes por categoria

dim(train)
View(test)
```

## División conjunto test y train

```{r}
set.seed(33)

train_perc <- 0.75
train_index <- createDataPartition(data$label, p=train_perc, list=FALSE)

data_train <- data[train_index,]
data_test <- data[-train_index,]
```


## Funciones de ayuda

```{r}
rotate <- function(x) t(apply(x, 2, rev))
```


```{r}
sample_4 <- matrix(as.numeric(data[4,-1]), nrow = 28, byrow = TRUE)
sample_7 <- matrix(as.numeric(data[7,-1]), nrow = 28, byrow = TRUE)
image(rotate(sample_4), col = grey.colors(255))
image(rotate(sample_7), col = grey.colors(255))
```
## Red neuronal sencilla

```{r}
simple_nnet <- multinom(label ~ ., data=data_train, MaxNWts=10000, decay=5e-3, maxit=100)
```


```{r}
prediction_simple_nnet <- predict(simple_nnet, data_test, type = "class")
prediction_simple_nnet[1:4]
data_test$label[1:4]

confussion_matrix <- table(data_test$label, prediction_simple_nnet)
confussion_matrix
```
```{r}
accuracy_simple_nnet <- mean(prediction_simple_nnet == data_test$label)
accuracy_simple_nnet

# Obtenemos un accuracy cercano al 90% no está mal pero vamos a intentar mejorarlo
```

