---
title: "Entrega"
author: "Victoria García Vega; Miguel Ángel González Caminero; Pablo Pérez Martín"
date: "2023-12-14"
output:
  html_document: 
    theme: cosmo
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Digit recognition

```{r}
library (caret)
library(ranger)
library(nnet)
library(mlbench)
```

```{r}
data <- read.csv("train.csv")
test_df <- read.csv("test.csv")

data$label <- as.factor(data$label)
summary(data$label)

dim(train)
#View(test_df)
```

## División conjunto test y train

```{r}
set.seed(33)

train_perc <- 0.75
train_index <- createDataPartition(data$label, p=train_perc, list=FALSE)

data_train <- data[train_index,]
data_test <- data[-train_index,]
```

## Funciones de ayuda

```{r}
rotate <- function(x) t(apply(x, 2, rev))
```

Mostramos un par de imagenes de prueba

```{r}
sample_4 <- matrix(as.numeric(data[4,-1]), nrow = 28, byrow = TRUE)
sample_7 <- matrix(as.numeric(data[7,-1]), nrow = 28, byrow = TRUE)
image(rotate(sample_4), col = grey.colors(255))

```

```{r}
image(rotate(sample_7), col = grey.colors(255))
```

## Random Forest

El primer algoritmo que vamos a utilizar es el de Random Forest, que consiste en construir múltiples árboles de decisión durante el entrenamiento y combinar sus resultados para obtener predicciones más precisas.

Para ello, vamos a utilizar la librería **ranger**, que es una versión optimizada de **randomForest**, con los siguientes parámetros:

-   *num.trees=50*: El número de árboles que hemos indicado es 50, pues al incrementar este valor el tiempo de ejecución crece significativamente, mientras que el accuracity se muestra prácticamente invariable.

-   *importance="impurity"*: este parámetro se utiliza para indicar si se deben calcular las importancias de las variables. Su valor por defecto es "none". Sin embargo, para nuestro modelo le hemos indicado que calcule la importancia de las variables basándose en la medida de impureza de Gini o ganancia de varianza.

```{r}
if (!file.exists("random_forest.rds")) {
  
  # Entrenamos modelo
  rf <- ranger(label ~ ., data = data_train, num.trees = 50, importance = "impurity")
  
  # Guardamos modelo
  saveRDS(rf, file = "random_forest.rds")
  
} else {
  # cargamos modelo 
  rf <- readRDS("random_forest.rds")
}

print(rf)
# importance(rf)
```

```{r}
prediction_rf<- predict(rf, data_test)

confussion_matrix_rf <- table(data_test$label, prediction_rf$predictions)
confussion_matrix_rf
```

```{r}
accuracy_rf <- mean(prediction_rf$predictions == data_test$label)
cat("Accuracy with random forest:", accuracy_rf) # 0.96
```

## Boosting

A continuación, usaremos tres algoritmos distintos de *boosting*: C5.0, AdaBoost.M1 y Boosted Linear Model.

Usaremos para ello la librería *caret* junto con las librerías *adabag*, *plyr*, *bst* y *C50*.

### Entrenamiento

```{r}
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(Sys.time())
metric <- "Accuracy"
```

#### C5.0

```{r}
grid <- expand.grid(trials = c(1, 10, 20),
                    model = c("tree", "rules"),
                    winnow = c(TRUE, FALSE))
if (file.exists("boosting_c50.rds")) {
  model_c50 <- readRDS(file = "boosting_c50.rds")
} else {
  model_c50 <- train(label ~ .,
                     data = data_train[1:1000, ],
                     method = "C5.0",
                     metric = metric,
                     tuneGrid = grid,
                     trControl = control)
  saveRDS(model_c50, file = "boosting_c50.rds")
}
```

#### AdaBoost.M1

```{r}
grid <- expand.grid(mfinal = (1:3) * 3,
                    maxdepth = c(1, 3),
                    coeflearn = c("Breiman"))
if (file.exists("boosting_adaboost.rds")) {
  model_adaboost <- readRDS(file = "boosting_adaboost.rds")
} else {
  model_adaboost <- train(label ~ .,
                          data = data_train[1:1000, ],
                          method = "AdaBoost.M1",
                          metric = metric,
                          tuneGrid = grid,
                          trControl = control)
  saveRDS(model_adaboost, file = "boosting_adaboost.rds")
}
```

#### Boosted Linear Model

```{r}
grid <- expand.grid(mstop = 150,
                    nu = 0.01)
if (file.exists("boosting_bstlm.rds")) {
  model_bstlm <- readRDS(file = "boosting_bstlm.rds")
} else {
  model_bstlm <- train(label ~ .,
                       data = data_train,
                       method = "BstLm",
                       metric = metric,
                       tuneGrid = grid,
                       trControl = control)
  saveRDS(model_bstlm, file = "boosting_bstlm.rds")
}
```

### Resultados

```{r}
results <- resamples(list(c50 = model_c50,
                          adaboost = model_adaboost,
                          bstlm = model_bstlm))
summary(results)
dotplot(results)
```

### Test

#### C5.0

```{r}
pred_c50 <- predict(model_c50, data_test[1:1000, ])
conf_matrix_c50 <- table(data_test[1:1000, ]$label, pred_c50)
```

```{r}
conf_matrix_c50
accuracy_c50 <- mean(pred_c50 == data_test[1:1000, ]$label)
cat("Accuracy with C5.0 boosting: ", accuracy_c50)
```

#### AdaBoost.M1

```{r}
pred_adaboost <- predict(model_adaboost, data_test[1:1000, ])
conf_matrix_adaboost <- table(data_test[1:1000, ]$label, pred_adaboost)
```

```{r}
conf_matrix_adaboost
accuracy_adaboost <- mean(pred_adaboost == data_test[1:1000, ]$label)
cat("Accuracy with AdaBoost.M1 boosting: ", accuracy_adaboost)
```


#### Boosted Linear Model

```{r}
pred_bstlm <- predict(model_bstlm, data_test)
conf_matrix_bstlm <- table(data_test$label, pred_bstlm)
```

```{r}
conf_matrix_bstlm
accuracy_bstlm <- mean(pred_bstlm == data_test$label)
cat("Accuracy with Boosted Linear Model boosting: ", accuracy_bstlm)
```

### Conclusión final

De las tres posibilidades de boosting, el método C5.0 es el que más precisión reporta (alrededor del 90%)

## Red neuronal sencilla

```{r}

if (!file.exists("simple_nnet_model.rds")) {
  
  # Entrenamos modelo
  simple_nnet <- multinom(label ~ ., data=data_train, MaxNWts=10000, decay=5e-3, maxit=100)
  
  # Guardamos modelo
  saveRDS(simple_nnet, file = "simple_nnet_model.rds")
  
} else {
  # cargamos modelo 
  simple_nnet <- readRDS("simple_nnet_model.rds")
}
```

```{r}
prediction_simple_nnet <- predict(simple_nnet, data_test, type = "class")
prediction_simple_nnet[1:4]
data_test$label[1:4]

confussion_matrix <- table(data_test$label, prediction_simple_nnet)
confussion_matrix
```

```{r}
accuracy_simple_nnet <- mean(prediction_simple_nnet == data_test$label)
cat("Accuracy with a simple neural network:", accuracy_simple_nnet) 

# Obtenemos un accuracy cercano al 90% no está mal pero vamos a intentar mejorarlo
```

## 
